<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 3.2.0">
  <meta name="generator" content="Hugo 0.52" />
  <meta name="author" content="Praveen Krishnan">

  
  
  
  
    
  
  <meta name="description" content="In recent years, in the field of vision and other AI problems, there has been a paradigm shift in the way we represent features. Feature learning has been a common buzzword due to the resurgence of neural networks with much bigger architectures, data and efficient optimization techniques. Deep Learning as referred to these learnable machines due to their enormous number of parameters has taken its own place in the field of machine learning with a large research community base, trying to solve complex real world problems.">

  
  <link rel="alternate" hreflang="en-us" href="https://kris314.github.io/teaching/featembed/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css" integrity="sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="https://kris314.github.io/index.xml" type="application/rss+xml" title="Praveen Krishnan">
  <link rel="feed" href="https://kris314.github.io/index.xml" type="application/rss+xml" title="Praveen Krishnan">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://kris314.github.io/teaching/featembed/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Praveen Krishnan">
  <meta property="og:url" content="https://kris314.github.io/teaching/featembed/">
  <meta property="og:title" content="Feature Learning and Embedding Techniques | Praveen Krishnan">
  <meta property="og:description" content="In recent years, in the field of vision and other AI problems, there has been a paradigm shift in the way we represent features. Feature learning has been a common buzzword due to the resurgence of neural networks with much bigger architectures, data and efficient optimization techniques. Deep Learning as referred to these learnable machines due to their enormous number of parameters has taken its own place in the field of machine learning with a large research community base, trying to solve complex real world problems."><meta property="og:image" content="https://kris314.github.io/img/portrait.jpg">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2017-05-20T00:00:00-07:00">
  
  <meta property="article:modified_time" content="2017-05-20T00:00:00-07:00">
  

  

  

  <title>Feature Learning and Embedding Techniques | Praveen Krishnan</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Praveen Krishnan</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#publications_selected">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/teaching/">
            
            <span>Teaching</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/files/cv.pdf">
            
            <span>CV</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

      

        

        

        

        

      </ul>

    </div>
  </div>
</nav>



<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      




<form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-3" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <span><i class="fas fa-bars"></i></span>
  </button>

  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/teaching/">Overview</a>

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/teaching/featembed/">Courses</a>
    <ul class="nav docs-sidenav">
      
      <li class="active">
        <a href="/teaching/featembed/">Feature Learning and Embedding Techniques</a>
      </li>
      
    </ul>
    

  </div>
  
  
</nav>

    </div>

    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      
      <p class="docs-toc-title">On this page</p>
      

      <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#bows-and-encoding-techniques"><strong>BoWs and Encoding Techniques</strong></a>
<ul>
<li><a href="#sub-topics">Sub-Topics</a>
<ul>
<li><a href="#course-material-link-https-researchweb-iiit-ac-in-praveen-krishnan-compreexam-slides-t1-bowandbeyond-pdf">Course Material: <a href="https://researchweb.iiit.ac.in/~praveen.krishnan/compreExam/slides/T1-BoWandBeyond.pdf" target="_blank">Link</a></a></li>
</ul></li>
</ul></li>
<li><a href="#convolutional-neural-networks"><strong>Convolutional neural networks</strong></a>
<ul>
<li><a href="#sub-topics-1">Sub-Topics</a>
<ul>
<li><a href="#course-material-link1-https-researchweb-iiit-ac-in-praveen-krishnan-compreexam-slides-t2-cnns-pdf-link2-https-researchweb-iiit-ac-in-praveen-krishnan-compreexam-slides-t3-moderncnnarchitectures-pdf-link3-https-researchweb-iiit-ac-in-praveen-krishnan-compreexam-slides-t4-distancemetriclearningbeyond0-1loss-pdf-link4-https-researchweb-iiit-ac-in-praveen-krishnan-compreexam-slides-t5-visualinstanceretrieval-pdf">Course Material: <a href="https://researchweb.iiit.ac.in/~praveen.krishnan/compreExam/slides/T2-CNNs.pdf" target="_blank">Link1</a>, <a href="https://researchweb.iiit.ac.in/~praveen.krishnan/compreExam/slides/T3-ModernCNNArchitectures.pdf" target="_blank">Link2</a>, <a href="https://researchweb.iiit.ac.in/~praveen.krishnan/compreExam/slides/T4-DistanceMetricLearningBeyond0-1Loss.pdf" target="_blank">Link3</a>, <a href="https://researchweb.iiit.ac.in/~praveen.krishnan/compreExam/slides/T5-VisualInstanceRetrieval.pdf" target="_blank">Link4</a></a></li>
</ul></li>
</ul></li>
<li><a href="#soft-attention-models-in-deep-networks"><strong>Soft Attention Models in Deep Networks</strong></a>
<ul>
<li><a href="#sub-topics-2">Sub-Topics</a>
<ul>
<li><a href="#course-material-link-https-researchweb-iiit-ac-in-praveen-krishnan-compreexam-slides-t6-softattentionmodelsindeepnetworks-pdf">Course Material: <a href="https://researchweb.iiit.ac.in/~praveen.krishnan/compreExam/slides/T6-SoftAttentionModelsinDeepNetworks.pdf" target="_blank">Link</a></a></li>
</ul></li>
</ul></li>
<li><a href="#word-embedding-techniques"><strong>Word Embedding techniques</strong></a>
<ul>
<li><a href="#sub-topics-3">Sub-Topics</a>
<ul>
<li><a href="#course-material-link-https-researchweb-iiit-ac-in-praveen-krishnan-compreexam-slides-t7-wordembedding-pdf">Course Material: <a href="https://researchweb.iiit.ac.in/~praveen.krishnan/compreExam/slides/T7-WordEmbedding.pdf" target="_blank">Link</a></a></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</nav>

      <ul class="nav toc-top">
        <li><a href="#">Back to top</a></li>
      </ul>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article" itemscope itemtype="http://schema.org/Article">

        <div class="docs-article-container">
          <h1 itemprop="name">Feature Learning and Embedding Techniques</h1>

          <div class="article-style" itemprop="articleBody">
            

<p>In recent years, in the field of vision and other AI problems, there has been a paradigm shift in the way we represent features. Feature learning has been a common buzzword due to the resurgence of neural networks with much bigger architectures, data and efficient optimization techniques. Deep Learning as referred to these learnable machines due to their enormous number of parameters has taken its own place in the field of machine learning with a large research community base, trying to solve complex real world problems. The course is divided into four parts:</p>

<h2 id="bows-and-encoding-techniques"><strong>BoWs and Encoding Techniques</strong></h2>

<p>In the first part of the course, we begin with the state of art feature descriptors used prior to deep learning (before 2012).</p>

<h3 id="sub-topics">Sub-Topics</h3>

<ul>
<li>Bag of Words (BoWs)

<ul>
<li>Learning visual vocabulary</li>
<li>Coding and Pooling</li>
<li>Ranking and Retrieval</li>
<li>Geometric Verification</li>
<li>Inspiration from IR domain</li>
</ul></li>
<li>Advanced coding schemes

<ul>
<li>Kernel code books, Sparse Coding and Locally constrained linear coding.</li>
<li>VLADs, Fisher Vector and Super Vector</li>
</ul></li>
</ul>

<h4 id="course-material-link-https-researchweb-iiit-ac-in-praveen-krishnan-compreexam-slides-t1-bowandbeyond-pdf">Course Material: <a href="https://researchweb.iiit.ac.in/~praveen.krishnan/compreExam/slides/T1-BoWandBeyond.pdf" target="_blank">Link</a></h4>

<h2 id="convolutional-neural-networks"><strong>Convolutional neural networks</strong></h2>

<p>In the major theme of the course, we start with fundamentals of a convolutional neural network (CNN), different layers, loss functions and also visualize the features learnt implicitly in each individual layer. We also discuss some of the major architectures proposed from 2012-2016 which got attention since they were winning entries of Large Scale Visual Recognition challenge. We also see how these architectures enable building image retrieval applications. Here we begin with the metric learning problem which uses ranking and similarity based loss functions. We later present a case study of some recent architectures used for instance based  retrieval using deep neural networks while also revisiting some of the concepts from pooling, feature aggregation used from prior deep learning era.</p>

<h3 id="sub-topics-1">Sub-Topics</h3>

<ul>
<li>Paradigm Shift: Feature engineering to feature learning

<ul>
<li>Simple feed forward network</li>
<li>Convolutional Network</li>
<li>Basics, Activation functions, Layers

<ul>
<li>Training and Loss functions</li>
<li>Generalization: Dropouts</li>
</ul></li>
<li>Visualizing CNNs using

<ul>
<li>Deconvnets and Saliency maps</li>
</ul></li>
<li>Transfer Learning</li>
<li>Some Practical Aspects</li>
</ul></li>
<li>Advanced NN architectures - Case Studies

<ul>
<li>LeNet, AlexNet, Overfeat, VGG, GoogLeNet, ResNet</li>
</ul></li>
<li>CNNs: Beyond 0/1 Loss Functions: Metric Learning

<ul>
<li>Basics in Metric Learning (Mahalanobis, LMNN)</li>
<li>Constrastive Loss (Siamese Architecture) and applications (dimensionality reduction and face verification)</li>
<li>Triplet Loss, Mining hard examples and application (face verification)</li>
</ul></li>
<li>Instance level retrieval and matching

<ul>
<li>Visual instance retrieval

<ul>
<li>Image retrieval using Deep Networks</li>
</ul></li>
<li>Neural Codes for Image Retrieval

<ul>
<li>Multi-Scale Orderless Pooling</li>
<li>Sum Pooled Convolutional Features</li>
<li>Integral Max Pooling</li>
<li>Magnet Loss</li>
</ul></li>
<li>Case Study: Deep Image Retrieval (Gordo et. al. ECCVâ€™16)</li>
</ul></li>
</ul>

<h4 id="course-material-link1-https-researchweb-iiit-ac-in-praveen-krishnan-compreexam-slides-t2-cnns-pdf-link2-https-researchweb-iiit-ac-in-praveen-krishnan-compreexam-slides-t3-moderncnnarchitectures-pdf-link3-https-researchweb-iiit-ac-in-praveen-krishnan-compreexam-slides-t4-distancemetriclearningbeyond0-1loss-pdf-link4-https-researchweb-iiit-ac-in-praveen-krishnan-compreexam-slides-t5-visualinstanceretrieval-pdf">Course Material: <a href="https://researchweb.iiit.ac.in/~praveen.krishnan/compreExam/slides/T2-CNNs.pdf" target="_blank">Link1</a>, <a href="https://researchweb.iiit.ac.in/~praveen.krishnan/compreExam/slides/T3-ModernCNNArchitectures.pdf" target="_blank">Link2</a>, <a href="https://researchweb.iiit.ac.in/~praveen.krishnan/compreExam/slides/T4-DistanceMetricLearningBeyond0-1Loss.pdf" target="_blank">Link3</a>, <a href="https://researchweb.iiit.ac.in/~praveen.krishnan/compreExam/slides/T5-VisualInstanceRetrieval.pdf" target="_blank">Link4</a></h4>

<h2 id="soft-attention-models-in-deep-networks"><strong>Soft Attention Models in Deep Networks</strong></h2>

<p>In the third part of the course, we delve into generative methods where we start with a LSTM model used as a predictive network. We later introduce a recent class of generative models called as variational autoencoders (VAE). We further introduce a new learning module called as attention interface which empowers learning with sequential data such as handwriting, text and speech. As a case study, we present the DRAW architecture which uses LSTM architecture and utilizes the concepts from VAE and attention mechanism to generate 2D images.</p>

<h3 id="sub-topics-2">Sub-Topics</h3>

<ul>
<li>Motivation for attention models</li>
<li>Primer on Prediction using RNNs

<ul>
<li>Handwriting prediction</li>
<li>Handwriting synthesis</li>
</ul></li>
<li>Basics in variational autoencoders</li>
<li>Deep Recurrent Attentive Writer</li>
</ul>

<h4 id="course-material-link-https-researchweb-iiit-ac-in-praveen-krishnan-compreexam-slides-t6-softattentionmodelsindeepnetworks-pdf">Course Material: <a href="https://researchweb.iiit.ac.in/~praveen.krishnan/compreExam/slides/T6-SoftAttentionModelsinDeepNetworks.pdf" target="_blank">Link</a></h4>

<h2 id="word-embedding-techniques"><strong>Word Embedding techniques</strong></h2>

<p>In the last part of the course, we introduce the concept of word embedding technique which is used in many NLP application to encode the discrete words into continous space where the semantic relationships are explicit. Here we discuss neural language modeling and present the prominent embedding technique using word2vec.</p>

<h3 id="sub-topics-3">Sub-Topics</h3>

<ul>
<li>Introduction to language modelling and classical topic modeling methods.</li>
<li>Neural language model and discussion on issues of tradtional softmax layer.</li>
<li>Recent word embedding models:-

<ul>
<li>C&amp;W Model</li>
<li>Word2Vec (Continous BoWs and Skip grams)

<ul>
<li>Hierarchical Softmax</li>
<li>Noise Contrastive Estimation</li>
<li>Negative Sampling</li>
</ul></li>
</ul></li>
</ul>

<h4 id="course-material-link-https-researchweb-iiit-ac-in-praveen-krishnan-compreexam-slides-t7-wordembedding-pdf">Course Material: <a href="https://researchweb.iiit.ac.in/~praveen.krishnan/compreExam/slides/T7-WordEmbedding.pdf" target="_blank">Link</a></h4>

          </div>

          

        </div>

        <div class="body-footer">
          Last updated on May 20, 2017
        </div>

      </article>

      <footer class="site-footer">
  

  <p class="powered-by">
    &copy; 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
  </p>
</footer>


    </main>
  </div>
</div>

    

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    

    
    

    
    

    
    
    
    
    
    
    
    
    <script src="/js/academic.min.d037ee5294b166a79dec317c58aea9cc.js"></script>

    

  </body>
</html>


